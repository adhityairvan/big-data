{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+---+\n",
      "|gender|race/ethnicity|parental level of education|       lunch|test preparation course|math score|reading score|writing score| id|\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+---+\n",
      "|female|       group B|          bachelor's degree|    standard|                   none|        72|           72|           74|  0|\n",
      "|female|       group C|               some college|    standard|              completed|        69|           90|           88|  1|\n",
      "|female|       group B|            master's degree|    standard|                   none|        90|           95|           93|  2|\n",
      "|  male|       group A|         associate's degree|free/reduced|                   none|        47|           57|           44|  3|\n",
      "|  male|       group C|               some college|    standard|                   none|        76|           78|           75|  4|\n",
      "|female|       group B|         associate's degree|    standard|                   none|        71|           83|           78|  5|\n",
      "|female|       group B|               some college|    standard|              completed|        88|           95|           92|  6|\n",
      "|  male|       group B|               some college|free/reduced|                   none|        40|           43|           39|  7|\n",
      "|  male|       group D|                high school|free/reduced|              completed|        64|           64|           67|  8|\n",
      "|female|       group B|                high school|free/reduced|                   none|        38|           60|           50|  9|\n",
      "|  male|       group C|         associate's degree|    standard|                   none|        58|           54|           52| 10|\n",
      "|  male|       group D|         associate's degree|    standard|                   none|        40|           52|           43| 11|\n",
      "|female|       group B|                high school|    standard|                   none|        65|           81|           73| 12|\n",
      "|  male|       group A|               some college|    standard|              completed|        78|           72|           70| 13|\n",
      "|female|       group A|            master's degree|    standard|                   none|        50|           53|           58| 14|\n",
      "|female|       group C|           some high school|    standard|                   none|        69|           75|           78| 15|\n",
      "|  male|       group C|                high school|    standard|                   none|        88|           89|           86| 16|\n",
      "|female|       group B|           some high school|free/reduced|                   none|        18|           32|           28| 17|\n",
      "|  male|       group C|            master's degree|free/reduced|              completed|        46|           42|           46| 18|\n",
      "|female|       group C|         associate's degree|free/reduced|                   none|        54|           58|           61| 19|\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "raw = spark.read.csv(\"StudentsPerformance.csv\", inferSchema = True, header = True)\n",
    "\n",
    "df = raw.select(\"*\").withColumn(\"id\", monotonically_increasing_id())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------+----------+-------------+-------------+-----------+\n",
      "| id|test preparation course|math score|reading score|writing score|preparation|\n",
      "+---+-----------------------+----------+-------------+-------------+-----------+\n",
      "|  0|                   none|        72|           72|           74|        0.0|\n",
      "|  1|              completed|        69|           90|           88|        1.0|\n",
      "|  2|                   none|        90|           95|           93|        0.0|\n",
      "|  3|                   none|        47|           57|           44|        0.0|\n",
      "|  4|                   none|        76|           78|           75|        0.0|\n",
      "|  5|                   none|        71|           83|           78|        0.0|\n",
      "|  6|              completed|        88|           95|           92|        1.0|\n",
      "|  7|                   none|        40|           43|           39|        0.0|\n",
      "|  8|              completed|        64|           64|           67|        1.0|\n",
      "|  9|                   none|        38|           60|           50|        0.0|\n",
      "| 10|                   none|        58|           54|           52|        0.0|\n",
      "| 11|                   none|        40|           52|           43|        0.0|\n",
      "| 12|                   none|        65|           81|           73|        0.0|\n",
      "| 13|              completed|        78|           72|           70|        1.0|\n",
      "| 14|                   none|        50|           53|           58|        0.0|\n",
      "| 15|                   none|        69|           75|           78|        0.0|\n",
      "| 16|                   none|        88|           89|           86|        0.0|\n",
      "| 17|                   none|        18|           32|           28|        0.0|\n",
      "| 18|              completed|        46|           42|           46|        1.0|\n",
      "| 19|                   none|        54|           58|           61|        0.0|\n",
      "+---+-----------------------+----------+-------------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---+-----------------------+----------+-------------+-------------+-----------+--------------------+\n",
      "| id|test preparation course|math score|reading score|writing score|preparation|            features|\n",
      "+---+-----------------------+----------+-------------+-------------+-----------+--------------------+\n",
      "|  0|                   none|        72|           72|           74|        0.0|[0.0,72.0,72.0,74.0]|\n",
      "|  1|              completed|        69|           90|           88|        1.0|[1.0,69.0,90.0,88.0]|\n",
      "|  2|                   none|        90|           95|           93|        0.0|[0.0,90.0,95.0,93.0]|\n",
      "|  3|                   none|        47|           57|           44|        0.0|[0.0,47.0,57.0,44.0]|\n",
      "|  4|                   none|        76|           78|           75|        0.0|[0.0,76.0,78.0,75.0]|\n",
      "|  5|                   none|        71|           83|           78|        0.0|[0.0,71.0,83.0,78.0]|\n",
      "|  6|              completed|        88|           95|           92|        1.0|[1.0,88.0,95.0,92.0]|\n",
      "|  7|                   none|        40|           43|           39|        0.0|[0.0,40.0,43.0,39.0]|\n",
      "|  8|              completed|        64|           64|           67|        1.0|[1.0,64.0,64.0,67.0]|\n",
      "|  9|                   none|        38|           60|           50|        0.0|[0.0,38.0,60.0,50.0]|\n",
      "| 10|                   none|        58|           54|           52|        0.0|[0.0,58.0,54.0,52.0]|\n",
      "| 11|                   none|        40|           52|           43|        0.0|[0.0,40.0,52.0,43.0]|\n",
      "| 12|                   none|        65|           81|           73|        0.0|[0.0,65.0,81.0,73.0]|\n",
      "| 13|              completed|        78|           72|           70|        1.0|[1.0,78.0,72.0,70.0]|\n",
      "| 14|                   none|        50|           53|           58|        0.0|[0.0,50.0,53.0,58.0]|\n",
      "| 15|                   none|        69|           75|           78|        0.0|[0.0,69.0,75.0,78.0]|\n",
      "| 16|                   none|        88|           89|           86|        0.0|[0.0,88.0,89.0,86.0]|\n",
      "| 17|                   none|        18|           32|           28|        0.0|[0.0,18.0,32.0,28.0]|\n",
      "| 18|              completed|        46|           42|           46|        1.0|[1.0,46.0,42.0,46.0]|\n",
      "| 19|                   none|        54|           58|           61|        0.0|[0.0,54.0,58.0,61.0]|\n",
      "+---+-----------------------+----------+-------------+-------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# preprocessing data\n",
    "indexer = StringIndexer(inputCol=\"test preparation course\", outputCol=\"preparation\")\n",
    "preprocessed = indexer.fit(df).transform(df)\n",
    "preprocessed.show()\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"preparation\", \"math score\",\"reading score\",\"writing score\"],\n",
    "    outputCol='features')\n",
    "preprocessed = assembler.transform(preprocessed)\n",
    "preprocessed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------+----------+-------------+-------------+-----------+--------------------+----------+\n",
      "| id|test preparation course|math score|reading score|writing score|preparation|            features|prediction|\n",
      "+---+-----------------------+----------+-------------+-------------+-----------+--------------------+----------+\n",
      "|  0|                   none|        72|           72|           74|        0.0|[0.0,72.0,72.0,74.0]|         3|\n",
      "|  1|              completed|        69|           90|           88|        1.0|[1.0,69.0,90.0,88.0]|         4|\n",
      "|  2|                   none|        90|           95|           93|        0.0|[0.0,90.0,95.0,93.0]|         1|\n",
      "|  3|                   none|        47|           57|           44|        0.0|[0.0,47.0,57.0,44.0]|         2|\n",
      "|  4|                   none|        76|           78|           75|        0.0|[0.0,76.0,78.0,75.0]|         4|\n",
      "|  5|                   none|        71|           83|           78|        0.0|[0.0,71.0,83.0,78.0]|         4|\n",
      "|  6|              completed|        88|           95|           92|        1.0|[1.0,88.0,95.0,92.0]|         1|\n",
      "|  7|                   none|        40|           43|           39|        0.0|[0.0,40.0,43.0,39.0]|         5|\n",
      "|  8|              completed|        64|           64|           67|        1.0|[1.0,64.0,64.0,67.0]|         3|\n",
      "|  9|                   none|        38|           60|           50|        0.0|[0.0,38.0,60.0,50.0]|         2|\n",
      "| 10|                   none|        58|           54|           52|        0.0|[0.0,58.0,54.0,52.0]|         2|\n",
      "| 11|                   none|        40|           52|           43|        0.0|[0.0,40.0,52.0,43.0]|         2|\n",
      "| 12|                   none|        65|           81|           73|        0.0|[0.0,65.0,81.0,73.0]|         3|\n",
      "| 13|              completed|        78|           72|           70|        1.0|[1.0,78.0,72.0,70.0]|         3|\n",
      "| 14|                   none|        50|           53|           58|        0.0|[0.0,50.0,53.0,58.0]|         2|\n",
      "| 15|                   none|        69|           75|           78|        0.0|[0.0,69.0,75.0,78.0]|         3|\n",
      "| 16|                   none|        88|           89|           86|        0.0|[0.0,88.0,89.0,86.0]|         1|\n",
      "| 17|                   none|        18|           32|           28|        0.0|[0.0,18.0,32.0,28.0]|         5|\n",
      "| 18|              completed|        46|           42|           46|        1.0|[1.0,46.0,42.0,46.0]|         2|\n",
      "| 19|                   none|        54|           58|           61|        0.0|[0.0,54.0,58.0,61.0]|         0|\n",
      "+---+-----------------------+----------+-------------+-------------+-----------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "kmeans = KMeans().setK(6).setSeed(1)\n",
    "model = kmeans.fit(preprocessed)\n",
    "\n",
    "y = model.transform(preprocessed)\n",
    "y.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.4574073166675022\n",
      "\n",
      "\n",
      "Cluster Centers: \n",
      "[ 0.24019608 59.19607843 61.39215686 60.07352941]\n",
      "[ 0.53333333 88.275      91.325      91.13333333]\n",
      "[ 0.21153846 49.21794872 51.42307692 49.28205128]\n",
      "[ 0.38223938 67.16602317 70.67953668 70.27799228]\n",
      "[ 0.48660714 76.59375    80.47767857 79.15178571]\n",
      "[ 0.10810811 32.13513514 35.97297297 33.59459459]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "evaluator = ClusteringEvaluator()\n",
    "silhouette = evaluator.evaluate(y)\n",
    "\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n",
    "\n",
    "\n",
    "centers = model.clusterCenters()\n",
    "print(\"\\n\\nCluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
